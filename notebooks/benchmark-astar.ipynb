{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bd48b04-4a7b-4375-900b-735c7bd4cad4",
   "metadata": {},
   "source": [
    "# Scikit-decide performance\n",
    "\n",
    "The aim of this notebook is to compare performance of scikit-decide and networkx on a given use case (shortest path in a graph with A* algorithm), try to explain differences and see if scikit-decide can run faster.  A* algorithm in network and scikit-decide are written in pure Python, and are very similar.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "A `run_graph.py` script was provided, it runs each method several times with different start and end points, prints the path length to check that all methods return the same result, and prints processing time of each method.  The benchmarked algorithms were:\n",
    "\n",
    "* `networkx`: calls `networkx.astar_path`\n",
    "* `astar`: calls `skdecide.hub.solver.lazy_astar.LazyAstar`\n",
    "* `stateful`: calls the same method, but `State` is defined as a class containing an `int`, whereas `State` is defined as an `int` in `astar`\n",
    "\n",
    "It is important when profiling code to run only the portion of code of interest.  It is possible to comment out some parts, but it is then very difficult to reproduce the exact same commands. Command-line arguments have been added to `run_graph.py`:\n",
    "\n",
    "    --repeat <int>         run searches for N different start and end points\n",
    "    --algo networkx|astar  run only this algorithm (can be repeated)\n",
    "    --output <filename>    write timings in a CSV file\n",
    "    --seed <int>           set random generator seed\n",
    "\n",
    "As shown above, `stateful` algorithm is not mentioned, it will be treated in a different manner.\n",
    "\n",
    "Timings are stored in CSV files so that this notebook can display plots instantaneously.  We give arguments of `run_graph.py` script so that anyone can reproduce these results.  This script randomly selects a start and end node, and finds the shortest path between these nodes with the requested methods.\n",
    "\n",
    "By default, each method is called 50 times with different start and end nodes, and we store in a CSV file the length of the solution (not used in this notebook, but may be useful) and the processing time of each method.  Profiling is run on 10 runs only, and on a single algorithm.  It is very important to understand that profiling has a very high overhead and may not be representative.  This gives hints to find hotspots, but benchmarking must always be performed without profiling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0772602c-018c-4fe4-8aa5-7137018f95af",
   "metadata": {},
   "source": [
    "Make sure that dependencies are installed. Bokeh is similar to matplotlib, but allows interactions (pan, zoom, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a20f33e-9d0b-462e-a318-06d3cc9acbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bokeh pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff53737-8397-499f-94a3-04467ed5ec8d",
   "metadata": {},
   "source": [
    "Import bokeh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482c7d5e-d87e-4404-af26-8b4c3728de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook\n",
    "from bokeh.layouts import row\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure, show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0aa830-6132-47ad-86ab-edf4c290e02e",
   "metadata": {},
   "source": [
    "Render plots directly in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94372e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b55561-b15b-410e-9bcb-6d542b352d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccaaf42-e6d6-45f3-a017-033feea7812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timings(timings: pd.DataFrame, reference: str, colors) -> None:\n",
    "    source = ColumnDataSource(timings)\n",
    "\n",
    "    others = [k for k in timings.columns.values if k != reference and k in colors]\n",
    "    ratio = ColumnDataSource(data=dict(\n",
    "        index = range(len(timings)),\n",
    "        **{ k: timings[k] / timings[reference] for k in others }\n",
    "    ))\n",
    "\n",
    "    p1 = figure()\n",
    "    p1.xaxis.axis_label = 'Run number'\n",
    "    p1.yaxis.axis_label = 'Time (s)'\n",
    "    for algo in timings.columns.values:\n",
    "        if algo not in colors:\n",
    "            continue\n",
    "        p1.line(x='index', y=algo, color=colors[algo], legend_label=algo, source=source)\n",
    "        p1.line(x=range(len(timings)), y=np.mean(source.data[algo]), color=colors[algo], line_dash=\"dashed\", legend_label=algo)\n",
    "        p1.line(x=range(len(timings)), y=np.median(source.data[algo]), color=colors[algo], line_dash=\"dotted\", legend_label=algo)\n",
    "    p1.legend.location = \"top_left\"\n",
    "    p1.legend.click_policy=\"hide\"\n",
    "\n",
    "    p2 = figure()\n",
    "    p2.xaxis.axis_label = 'Run number'\n",
    "    p2.yaxis.axis_label = f'Ratio time(algo)/time({reference})'\n",
    "    for algo in others:\n",
    "        p2.line(x='index', y=algo, color=colors[algo], legend_label=algo, source=ratio)\n",
    "        p2.line(x=range(len(timings)), y=np.mean(ratio.data[algo]), color=colors[algo], line_dash=\"dashed\", legend_label=algo)\n",
    "        p2.line(x=range(len(timings)), y=np.median(ratio.data[algo]), color=colors[algo], line_dash=\"dotted\", legend_label=algo)\n",
    "    p2.legend.location = \"top_left\"\n",
    "    p2.legend.click_policy=\"hide\"\n",
    "\n",
    "    show(row(p1, p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e60653-e2f4-4702-a2fc-16b96389c5dd",
   "metadata": {},
   "source": [
    "## Comparisons between scikit-decide and networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ed4712-50ea-4e9e-a603-e81ea09bb712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file had been generated by: python run_graph.py --graph_file USA-road-d.NY.gr --repeat 100 --output ref.csv --seed 0\n",
    "master = pd.read_csv(\"ref.csv\", sep=\" \", header=None, names=['length', 'networkx', 'astar'])\n",
    "master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b571ada-f27d-4a41-b16a-c65b863e9246",
   "metadata": {},
   "source": [
    "Define line colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1029cf-16b1-4108-a0a7-d6b72c3dc222",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {'networkx': 'green', 'astar': 'red'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8d9345-55fc-4aac-9eee-08521c4601ad",
   "metadata": {},
   "source": [
    "Left plot shows processing time of each method for different start and end nodes.  Dashed (resp. dotted) line is the mean (resp. median) on all runs. We see that scikit-decide is much slower than networkx, and the right plot shows how many times it is slower. Pikes are not meaningful, they always happen when processing time is very slow and thus timing is inaccurate, this is why median is also displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71176181-88e1-4ffc-8be8-ab2ebfedee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_timings(timings=master, reference=\"networkx\", colors=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e23c514-671c-4aa1-af73-4bb13e5fee0d",
   "metadata": {},
   "source": [
    "On my computer, `astar` is about 2.8 times slower than `networkx`.  Even with the same random seed, timings may vary when running `run_graph.py` several times, it is a good idea plot timings of different runs and keep a representative one (on some run, your computer may get busy by doing some other stuff, for instance).  For illustration purpose, it may be interesting to gather timings of all `networkx` runs below into a single plot to display these differences.  But these differences do not matter much if one is careful to keep representative timings.\n",
    "You may find different values when running `run_graph.py` on your computer, but normally all timings in this notebook should follow the same trend.\n",
    "\n",
    "In order to improve performance, it is import to profile code and not rely on some intuition.  We run only `astar` method, on 10 iterations:\n",
    "\n",
    "    python -m cProfile -o prof-ref.out run_graph.py --graph_file USA-road-d.NY.gr --repeat 10 --algo astar --seed 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08762fe5-78d5-4fbe-89e5-b3577ca89347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404d3f15-61d0-43be-8edc-5b09cce759c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pstats.Stats(\"prof-ref.out\")\n",
    "p.strip_dirs().sort_stats('cumtime').print_stats(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec2b10d-027d-4aa0-a5c3-6402353187f6",
   "metadata": {},
   "source": [
    "Here are some remarks about this output:\n",
    "* First of all, we must be very cautious when reading these profiles.  They give hints to where to look at, but performance must always be checked afterwards without profiling.\n",
    "* Output is not easy to read, this is not a call graph (graphic tools like snakeviz are useful to display a call graph)\n",
    "* `solve` takes 22.6s, `extender` 15.6s and 7s are spent elsewhere\n",
    "* `get_transition_value` is surprisingly heavy.  It creates a `Value` which inherits from `Generic`, and we see that most of the time is spent in `typing.py:868(__new__)`.  But one must be very cautious here: by looking at figures, one may think that this inheritance costs 4.1s out of 5.5s, but there are 1667334 calls to `get_transition_value` and 4008450 calls to `typing.py:868(__new__)`, so the real time spent in `__new__` is 4.129*1667334/4008450=1.7s when it is called from `get_transition_value`.  Still high, but not as high as it looked like first.\n",
    "\n",
    "\n",
    "We will now display timings when `State` is a class (this was the `stateful` algorithm in original `run_graph.py`):\n",
    "\n",
    "```\n",
    "class GraphState:\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self.id\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.id == other.id\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab09b541-9035-4f8a-b210-4ee65e3c7d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file had been generated by: python run_graph.py --graph_file USA-road-d.NY.gr --repeat 100 --output stateful.csv --seed 0\n",
    "stateful = pd.read_csv(\"stateful.csv\", sep=\" \", header=None, names=['length', 'networkx', 'astar'])\n",
    "plot_timings(timings=stateful, reference=\"networkx\", colors=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf19f2fc-fcf5-4491-9ed9-befced2a5379",
   "metadata": {},
   "source": [
    "Now `astar` is 3.8 slower than `networkx` instead of 2.8.  This means that the overhead of using a class for `State` is not negligible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133b3479-117f-47b4-a305-c88f919bb0de",
   "metadata": {},
   "source": [
    "In order to evaluate the cost of deriving from `Generic`, we make `GraphState` a dataclass similar to `Value`:\n",
    "```\n",
    "from dataclasses import dataclass\n",
    "from typing import Generic\n",
    "@dataclass\n",
    "class GraphState(Generic[T]):\n",
    "    id: T\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self.id\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.id == other.id\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af91d65-4705-412c-9fe8-dc2196947a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file generated by: python run_graph.py --graph_file USA-road-d.NY.gr --repeat 100 --output dataclass-generic.csv --seed 0\n",
    "dataclassgeneric = pd.read_csv(\"dataclass-generic.csv\", sep=\" \", header=None, names=['length', 'networkx', 'astar'])\n",
    "plot_timings(timings=dataclassgeneric, reference=\"networkx\", colors=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04359009-b4d7-4eab-ae7b-bda469d03d93",
   "metadata": {},
   "source": [
    "`astar` now runs 4.35 times slower than `networkx`!\n",
    "\n",
    "Here is a summary of our timings:\n",
    "\n",
    "| State | comparison with networkx |\n",
    "| --- | --- |\n",
    "| int | x2.8 |\n",
    "| normal class | x3.8 |\n",
    "| dataclass with Generic | x4.35 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167f0c03-37c8-4772-b499-9159e61819ac",
   "metadata": {},
   "source": [
    "In original profile we see that `get_next_state` is called twice `get_transition_value`, so if we find a way to change `Value` into a float, we may expect a slower gain, but that sounds interesting anyway.  `State` is set again to an `int`.\n",
    "\n",
    "Instead of changing `Value` to a float, a simpler option in order to test this change is to introduce a method `_get_transition_cost` in `dynamics.py`.  This will break many things (we must choose between reward and cost, and C++ code has not been updated).  Again this change is applied only to have an idea of the speedup, so that developers can have insights to choose the best option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c64972-1af2-4354-9124-6f5f502f42be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file generated by: python run_graph.py --graph_file USA-road-d.NY.gr --repeat 100 --output value.csv --seed 0\n",
    "value = pd.read_csv(\"value.csv\", sep=\" \", header=None, names=['length', 'networkx', 'astar'])\n",
    "plot_timings(timings=value, reference=\"networkx\", colors=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12485f9-25cc-43aa-942a-7e80d4c3bd32",
   "metadata": {},
   "source": [
    "There is a noticeable gain, slowdown is x2.4 instead of x2.8, but `heuristic` also creates `Value` instances.  We modify it in `lazy_astar.py` to return a float instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c56e14-0787-49f0-8cc5-c75fccd3d818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file generated by: python run_graph.py --graph_file USA-road-d.NY.gr --repeat 100 --output heuristic.csv --seed 0\n",
    "heuristic = pd.read_csv(\"heuristic.csv\", sep=\" \", header=None, names=['length', 'networkx', 'astar'])\n",
    "plot_timings(timings=heuristic, reference=\"networkx\", colors=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1f5fe1-6182-4c9b-9e06-f2e89765d734",
   "metadata": {},
   "source": [
    "That is interesting, by replacing `Value` by a float, we were able to drop slowdown from x2.8 to almost x2.  We profile again after these changes:\n",
    "\n",
    "    python -m cProfile -o prof-heuristic.out run_graph.py --graph_file USA-road-d.NY.gr --repeat 10 --algo astar --seed 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fd53c5-9867-4342-b66b-63c0d1ca289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pstats.Stats(\"prof-heuristic.out\")\n",
    "p.strip_dirs().sort_stats('cumtime').print_stats(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13feff57-04ed-44c9-b25b-617fa81a8b9c",
   "metadata": {},
   "source": [
    "We see that `get_applicable_actions` takes about 30% execution time of `extender`.  It is not clear from output above, but snakeviz shows that an important part of the time is spent in creating `ActionSpace` instances, because it inherits from `Generic`.  We remove this inheritance for all `*Space*` classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cd93c4-6deb-4157-8bc7-922ffac5bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file generated by: python run_graph.py --graph_file USA-road-d.NY.gr --repeat 100 --output space.csv --seed 0\n",
    "space = pd.read_csv(\"space.csv\", sep=\" \", header=None, names=['length', 'networkx', 'astar'])\n",
    "plot_timings(timings=space, reference=\"networkx\", colors=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cec293-508b-409e-a91f-eb5eb039a08b",
   "metadata": {},
   "source": [
    "We modify `_get_applicable_actions` to call `ActionSpace` with a generator instead of a list.  It looks like result of getters are consumed once, thus a generator may be fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bcd8e5-1d8e-4c01-bb8f-d15a0a8c0e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file generated by: python run_graph.py --graph_file USA-road-d.NY.gr --repeat 100 --output actions.csv --seed 0\n",
    "actions = pd.read_csv(\"actions.csv\", sep=\" \", header=None, names=['length', 'networkx', 'astar'])\n",
    "plot_timings(timings=actions, reference=\"networkx\", colors=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e1b6c3-b2ca-4e96-8877-bf9d966962dc",
   "metadata": {},
   "source": [
    "When looking at `extender` code, one see that two intermediate lists are created to return a third list\n",
    "\n",
    "    def extender(node, label, explored):\n",
    "       neigh = [(self._domain.get_next_state(node, a), a)\n",
    "                 for a in self._domain.get_applicable_actions(node).get_elements()]\n",
    "        neigh_not_explored = [(n, a) for n, a in neigh if n not in explored]\n",
    "        cost_labels = [(n, self._domain.get_transition_cost(node, a, n), {'action': a})\n",
    "                       for n, a in neigh_not_explored]\n",
    "        return cost_labels\n",
    "\n",
    "Its output is consumed in a `for` loop, so it can be rewritten as a generator without any intermediate list\n",
    "\n",
    "    def extender(node, label, explored):\n",
    "        for a in self._domain.get_applicable_actions(node).get_elements():\n",
    "            n = self._domain.get_next_state(node, a)\n",
    "            if n not in explored:\n",
    "                yield (n, self._domain.get_transition_cost(node, a, n), {'action': a})\n",
    "\n",
    "Replacing comprehension lists by generators is not always a good idea, readability may be more important than pure performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9a1d23-961d-477a-b5bc-35d6c73342f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file generated by: python run_graph.py --graph_file USA-road-d.NY.gr --repeat 100 --output extender.csv --seed 0\n",
    "extender = pd.read_csv(\"extender.csv\", sep=\" \", header=None, names=['length', 'networkx', 'astar'])\n",
    "plot_timings(timings=extender, reference=\"networkx\", colors=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b933fe-c4d1-4963-9ec4-28d151d5e09a",
   "metadata": {},
   "source": [
    "Ratio time goes from x1.75 down to x1.6, this change looks interesting.  Of course it will provide a lower speedup if applied on current `master` since the relative time spent in this portion of code is lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c57ffd3-acfd-4b89-abdf-734192b823bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pstats.Stats(\"prof-extender.out\")\n",
    "p.strip_dirs().sort_stats('cumtime').print_stats(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f28e13-ba1d-47a3-9205-be43fbf2420f",
   "metadata": {},
   "source": [
    "We see that `_get_applicable_actions_from` is still a hotspot.  In `extender` method, this an `ActionSpace` instance is created, but this is only a proxy. We replace\n",
    "\n",
    "    (in ActionSpace)\n",
    "    def _get_applicable_actions_from(self, memory: D.T_memory[D.T_state]) -> Space[D.T_event]:\n",
    "        return ActionSpace(self.next_state_map[memory].keys())\n",
    "    (in LazyAstar)\n",
    "    def extender(node, label, explored):\n",
    "       for a in self._domain.get_applicable_actions(node).getElements():\n",
    "           ...\n",
    "\n",
    "by\n",
    "\n",
    "    (in ActionSpace)\n",
    "    def _get_applicable_actions_from(self, memory: D.T_memory[D.T_state]) -> Iterable[D.T_event]:\n",
    "        return self.next_state_map[memory].keys()\n",
    "    (in LazyAstar)\n",
    "    def extender(node, label, explored):\n",
    "       for a in self._domain.get_applicable_actions(node):\n",
    "           ...\n",
    "\n",
    "To make this work, all `contains` methods must be renamed to `__contains__`.  BTW it is better to use Pythonic names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e82ae-7c66-4fe6-b94c-e7b6556ef043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file generated by: python run_graph.py --graph_file USA-road-d.NY.gr --repeat 100 --output contains.csv --seed 0\n",
    "contains = pd.read_csv(\"contains.csv\", sep=\" \", header=None, names=['length', 'networkx', 'astar'])\n",
    "plot_timings(timings=contains, reference=\"networkx\", colors=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2a0320-5d42-4468-a050-103b82bed1c9",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "Here is a summary of timings with different code changes:\n",
    "\n",
    "| changes in code | comparison with networkx | relative speed-up |\n",
    "| --- | --- | --- |\n",
    "| reference | x2.8 | na |\n",
    "| do not create Value instances | x2 | 1.4 |\n",
    "| do not let `ActionSpace` inherit from `Generic` | x1.8 | 1.1 |\n",
    "| pass a generator to `ActionSpace` | x1.75 | 1.1 |\n",
    "| rewrite `extender` to not build lists | x1.6 | 1.1 |\n",
    "| do not create ActionSpace instances | x1.5 | 1.1 |\n",
    "\n",
    "Most of these changes tell the same story: creation of many instances of small objects may become a bottleneck.  This is not inherent to Python, for instance unboxing in Java induces the same performance problems.  In fact, this is a general problem with object oriented programming.  Is it more important to have clean code with very good encapsulation, or no encapsulation at all for best performances?\n",
    "There is no definitive answer, it depends on your priority.  Current code is clean; if performance is not critical, it is reasonable to leave it as is.  If performance is an issue, then some design changes are necessary.\n",
    "\n",
    "All methods defined in API (or at least the most used ones) should be examined to see if they really need to return a new instance.  If this instance is only a wrapper to an iterable, maybe it could return an `Iterable` instead?  If a class is really needed, another option is to pass a mutable argument instead of returning a new instance.  Of course this is ugly from an object-oriented programming perspective, this is why it must be balanced with expected performance gains.\n",
    "\n",
    "For instance, if the `Value` class cannot be removed, we can replace\n",
    "\n",
    "    def _get_transition_value(self, memory: D.T_memory[D.T_state],\n",
    "                              event: D.T_event,\n",
    "                              next_state: Optional[D.T_state] = None) -> Value[D.T_value]:\n",
    "        return Value(cost=self.next_state_attributes[memory][event][self.attribute_weight])\n",
    "\n",
    "by\n",
    "\n",
    "    def _compute_transition_value(self, out: Value[D.T.value], memory: D.T_memory[D.T_state],\n",
    "                                  event: D.T_event, next_state: Optional[D.T_state] = None) -> None:\n",
    "        out.cost = self.next_state_attributes[memory][event][self.attribute_weight]\n",
    "\n",
    "In order to test this solution, changes on `Value` are first reverted, then it uses `@property` decorator to handle mutation of cost and reward.  The `heuristic` function should also accept a mutable `Value` argument, but for simplicity reasons it returns a float instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eebd40-234c-4289-970e-eb179af7629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file generated by: python run_graph.py --graph_file USA-road-d.NY.gr --repeat 100 --output compute.csv --seed 0\n",
    "compute = pd.read_csv(\"compute.csv\", sep=\" \", header=None, names=['length', 'networkx', 'astar'])\n",
    "plot_timings(timings=compute, reference=\"networkx\", colors=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7edf9f4-a4a8-4720-9ad0-55bb39ea81c9",
   "metadata": {},
   "source": [
    "This solution is a little bit slower than replacing `Value` by a float (x1.6 vs. x1.5), but it can take into account cost and reward.  For reference, here are timings when all other changes are applied but `Value` is kept as in `master`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d1e6b3-ee48-4807-89d7-f73161f62794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file generated by: python run_graph.py --graph_file USA-road-d.NY.gr --repeat 100 --output revert-value.csv --seed 0\n",
    "revert = pd.read_csv(\"revert-value.csv\", sep=\" \", header=None, names=['length', 'networkx', 'astar'])\n",
    "plot_timings(timings=revert, reference=\"networkx\", colors=colors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
